{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ff09b5-5722-47d1-96e5-87da072fde34",
   "metadata": {},
   "source": [
    "# The Decomposition Pattern - Breaking Down Big Problems\n",
    "\n",
    "Hello everyone, let's now explore the **Decomposition Pattern**, which can be very useful in tackling more complex problems.\n",
    "\n",
    "The core idea is simple but powerful: **Don't solve one big problem. Solve many small problems.**\n",
    "\n",
    "We break down a complex task into a sequence of smaller, focused sub-tasks. Each sub-task is handled by its own dedicated prompt, creating a \"pipeline\" where the output of one step becomes the input for the next.\n",
    "\n",
    "This notebook will demonstrate this by building a three-step pipeline for a common developer workflow:\n",
    "\n",
    "1. **Step 1:** Identify bugs in a piece of code.\n",
    "2. **Step 2:** Refactor the code to fix the identified bugs.\n",
    "3. **Step 3:** Generate unit tests for the newly refactored code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c353c8-db68-449a-9f41-dd0a24fac5f8",
   "metadata": {},
   "source": [
    "## The Task and Helper Functions\n",
    "\n",
    "First, let's define our helper functions and the initial \"buggy\" code that we will process through our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a656ec9-3173-490f-9f8a-f702ebb11bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import inspect\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"openai/gpt-4o-mini\"\n",
    "MAX_TOKENS_DEFAULT = 500\n",
    "\n",
    "def get_completion(\n",
    "    prompt,\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS_DEFAULT,\n",
    "    **kwargs\n",
    "):\n",
    "    if \"gpt-5\" in model:\n",
    "        kwargs[\"max_completion_tokens\"] = max_tokens\n",
    "    else:\n",
    "        kwargs[\"max_tokens\"] = max_tokens\n",
    "        \n",
    "    parsed_messages = []\n",
    "\n",
    "    if type(prompt) is str:\n",
    "        parsed_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        parsed_messages = prompt\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=parsed_messages,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_average_score(student_records):\n",
    "    total_score = 0\n",
    "    for record in student_records:\n",
    "        total_score += record['score']\n",
    "\n",
    "    return total_score / len(student_records)\n",
    "\n",
    "CODE_TO_PROCESS = inspect.getsource(get_average_score)\n",
    "\n",
    "print(\"Setup complete. Helper functions and code context are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e4c43-0ca9-47ef-8e13-970d70d21227",
   "metadata": {},
   "source": [
    "## Bug Identification\n",
    "\n",
    "Our first prompt is highly focused. Its only job is to analyze the code and identify potential bugs. We'll ask for the output in JSON format so we can easily parse it for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45faf71-3494-4c44-bd46-c9d8e0212024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4f5ad9-302a-4a8a-abaf-0d2515bb95e0",
   "metadata": {},
   "source": [
    "## Refactoring\n",
    "\n",
    "Now, we create our second prompt. Its context includes **both** the original code and the list of bugs we identified in Step 1. The task is to fix these specific issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34319eb0-d48b-4083-ab75-419d006ac78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb605379-ce38-4e65-a02c-bb073ef7b86e",
   "metadata": {},
   "source": [
    "## Test Generation\n",
    "\n",
    "Finally, our third prompt takes the **refactored code from Step 2** as its context. Its single, focused goal is to generate a comprehensive suite of unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b983b5-ad7d-40a6-bdfe-af5e06362b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607824e-f69d-4c8c-bd0d-023087419bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
