{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d50aa0-7b6c-4517-b6c1-8216db575aa8",
   "metadata": {},
   "source": [
    "# Understanding Tokenization\n",
    "\n",
    "Hello and welcome! This notebook will give you a hands-on feel for **tokenization**, an important concept when working with Large Language Models.\n",
    "\n",
    "As we discussed, tokenization is the process of breaking text down into the smaller units, or \"tokens,\" that an LLM can actually understand. These tokens can be words, parts of words, or even just punctuation and spaces.\n",
    "\n",
    "Understanding how your text is converted into tokens is the key to mastering prompt engineering. It helps explain:\n",
    "\n",
    "- **Cost:** Why some prompts are more expensive than others.\n",
    "- **Context Windows:** Why a model has a finite \"memory.\"\n",
    "- **Model Behavior:** Why a small change in a word can lead to a very different result.\n",
    "\n",
    "In this notebook, we'll use `tiktoken`, OpenAI's official tokenizer library, to see exactly how this process works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cd560-4198-4bac-8736-0d492e7de5f7",
   "metadata": {},
   "source": [
    "## Loading the Right Tokenizer\n",
    "\n",
    "Different models use different tokenization rules. Therefore, the first step is always to load the specific tokenizer that corresponds to the model you intend to use. Since we will be using `gpt-4o-mini` in our future examples, let's load its tokenizer.\n",
    "\n",
    "> Best Practice: Always match your tokenizer to your model to get an accurate token count and representation. The `tiktoken.encoding_for_model()` function makes this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbabab4-4337-4032-9000-dfbf5561fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "606d2c98-d97b-4c2e-8e34-a4b76d679896",
   "metadata": {},
   "source": [
    "## Tokenizing a Simple Sentence\n",
    "\n",
    "Let's start with a basic example. We will take a simple English sentence and see how the tokenizer breaks it down. The `.encode()` method converts our human-readable string into a list of integers, where each integer is a unique ID for a specific token.\n",
    "\n",
    "We can then decode these integers one by one to see exactly what text each token represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4cdb3-c31c-4c3b-bcbe-ea57cfbcb4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34cd4ba4-05f2-4fdb-b4a6-2b20472b113c",
   "metadata": {},
   "source": [
    "## Tokenizing Complex or Uncommon Words\n",
    "\n",
    "Now, what happens with a word that might not be in the tokenizer's dictionary, like \"Tokenization\"? Instead of failing, the tokenizer breaks it down into smaller, recognizable sub-words. This allows the model to handle any word imaginable.\n",
    "\n",
    "This is a critical concept: **one word does not always equal one token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74128fa0-8511-45b4-8110-431580b5a9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "322196fc-6381-4d38-8017-d1e2beb3ffde",
   "metadata": {},
   "source": [
    "## Tokenizing Code\n",
    "\n",
    "Finally, let's see how tokenization applies to computer code. The process is exactly the same. The tokenizer breaks down the code into its constituent parts, including keywords, variable names, operators, and whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549b742-7552-4f71-be28-1c1a2ebb98e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893e0dd-117a-4549-b95c-e505a42d16a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
