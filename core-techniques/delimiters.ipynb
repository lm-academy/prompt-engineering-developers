{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b25fc04-981a-4d01-a68b-289774c76306",
   "metadata": {},
   "source": [
    "# The Power of Delimiters\n",
    "\n",
    "Welcome! We know that a good prompt is built on the \"Three Pillars\" of Instruction, Context, and Constraints. But how do we organize these pillars within the prompt itself to ensure the model understands where one ends and the next begins?\n",
    "\n",
    "The answer is one of the simplest yet most effective techniques in prompt engineering: **using delimiters.**\n",
    "\n",
    "A delimiter is just a set of characters that marks the boundary of a piece of text. By using them, you transform your prompt from a confusing \"wall of text\" into a structured, well-organized document that is easy for the model to parse. This simple act dramatically increases the reliability of your outputs.\n",
    "\n",
    "In this notebook, we'll see the power of delimiters in action. We'll start with a poorly structured prompt and show how adding different types of delimiters makes it far more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edd81d-223d-458f-a8c3-9c3a0762bba1",
   "metadata": {},
   "source": [
    "## Setup: Helper Functions and Context\n",
    "\n",
    "First, let's set up our reusable helper functions and define the context for our task. The task will be a common one for developers: **summarizing a technical JSON API response into a human-readable bug report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11779d6-91c0-4d1a-b3fa-46149f0bddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"openai/gpt-4o-mini\"\n",
    "MAX_TOKENS_DEFAULT = 200\n",
    "\n",
    "def get_completion(\n",
    "    prompt,\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS_DEFAULT,\n",
    "    **kwargs\n",
    "):\n",
    "    parsed_messages = []\n",
    "\n",
    "    if type(prompt) is str:\n",
    "        parsed_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        parsed_messages = prompt\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=parsed_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- Our Context Data ---\n",
    "\n",
    "bug_ticket_json = {\n",
    "  \"ticket_id\": \"BUG-4521\",\n",
    "  \"status\": \"Open\",\n",
    "  \"priority\": \"High\",\n",
    "  \"component\": \"api-v2\",\n",
    "  \"title\": \"User authentication fails with expired token\",\n",
    "  \"logs\": [\n",
    "    {\"timestamp\": \"2024-07-26T10:00:15Z\", \"level\": \"ERROR\", \"message\": \"Token validation failed: expired\"},\n",
    "    {\"timestamp\": \"2024-07-26T10:00:15Z\", \"level\": \"INFO\", \"message\": \"Attempting re-authentication for user: user_abc\"}\n",
    "  ],\n",
    "  \"reporter\": \"dev_jane\"\n",
    "}\n",
    "\n",
    "# Convert the Python dict to a JSON string for use in the prompt\n",
    "bug_ticket_str = json.dumps(bug_ticket_json, indent=2)\n",
    "\n",
    "print(\"Helper functions and context data are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9b68a-d416-47f4-9d6c-08742e5ae221",
   "metadata": {},
   "source": [
    "## The \"Before\": A Poorly Structured Prompt\n",
    "\n",
    "Let's start by creating a prompt with no clear structure. We'll blend the instruction, the JSON data, and our constraints into a single paragraph. This is a common mistake that can confuse the model and lead to unreliable results, especially when using cheaper, less powerful models. **This can also confuse us, as we need to be much more careful when inspecting and modifying the prompt!**\n",
    "\n",
    "The model might get this right sometimes, but it's risky. It has to work harder to figure out what part of the prompt is the instruction versus the data to be operated on. This can lead to errors, especially with more complex inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ee765-a2c9-4433-a588-e3694295875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Please summarize the following bug ticket data for a report. {bug_ticket_str},\n",
    "and it should start with the ticket ID and title. Mention the priority and\n",
    "the affected component, but do not include the raw logs in the final summary.\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response_unstructured = get_completion(unstructured_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4cffa-f086-4731-8798-f92bcaf03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_unstructured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760bd24-8ce8-4246-a4e3-01e28613cdd9",
   "metadata": {},
   "source": [
    "## The \"After\": Adding Structure with Delimiters\n",
    "\n",
    "Now, let's refactor the *exact same prompt* using different delimiter styles. Notice how much clearer and more organized the prompts become. This clarity is valuable for you as a developer and for the model as the processor.\n",
    "\n",
    "### Delimiter Style 1: Markdown Headers\n",
    "\n",
    "Using Markdown-style headers (`###`) is highly readable and is an excellent way to label the different pillars of your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a56fd-eeeb-45c8-869d-11ee07f7dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_markdown = dedent(f\"\"\"\n",
    "# INSTRUCTION\n",
    "Summarize the bug ticket data into a single paragraph for a report.\n",
    "\n",
    "# TICKET DATA\n",
    "{bug_ticket_str}\n",
    "\n",
    "# CONSTRAINTS\n",
    "* The summary must be a single paragraph.\n",
    "* Start the summary with the ticked ID and the title.\n",
    "* Mention the priority and the affected component.\n",
    "* Do not include the raw logs in the final summary.\n",
    "\"\"\")\n",
    "\n",
    "response_md = get_completion(prompt_with_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6de73-a8de-4864-aeb0-0a5eed22739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3c2c0-02c1-4ad8-9bf7-407e5f16d8e5",
   "metadata": {},
   "source": [
    "### Delimiter Style 2: XML Tags\n",
    "\n",
    "Using custom XML-style tags is extremely explicit and unambiguous for the model. It clearly marks the beginning and end of each block of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23150ec1-6f10-4c98-a6eb-32a33c44fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_xml = dedent(f\"\"\"\n",
    "<instructions>\n",
    "Summarize the bug ticket data into a single paragraph for a report.\n",
    "</instructions>\n",
    "\n",
    "<ticket_data>\n",
    "{bug_ticket_str}\n",
    "</ticket_data>\n",
    "\n",
    "<constraints>\n",
    "* The summary must be a single paragraph.\n",
    "* Start the summary with the ticked ID and the title.\n",
    "* Mention the priority and the affected component.\n",
    "* Do not include the raw logs in the final summary.\n",
    "</constraints>\n",
    "\"\"\")\n",
    "\n",
    "response_xml = get_completion(prompt_with_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8dbed-8ebb-4182-82e8-bd177ac3f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e01c5d-277c-4f0d-9a82-2ca8cad2d278",
   "metadata": {},
   "source": [
    "### Delimiter Style 3: Triple Backticks\n",
    "\n",
    "Triple backticks are a developer's favorite. Using them with a language identifier (like `json`) gives the model a strong hint about the format of the context data, which can further improve parsing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee5420-1c83-463d-9bbc-9632b208086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_backticks = dedent(f\"\"\"\n",
    "Summarize the bug ticket data into a single paragraph for a report.\n",
    "\n",
    "```json\n",
    "{bug_ticket_str}\n",
    "```\n",
    "\n",
    "Please follow the following rules:\n",
    "* The summary must be a single paragraph.\n",
    "* Start the summary with the ticked ID and the title.\n",
    "* Mention the priority and the affected component.\n",
    "* Do not include the raw logs in the final summary.\n",
    "\"\"\")\n",
    "\n",
    "response_backticks = get_completion(prompt_with_backticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecfb5a0-9bdd-4f79-aee1-88ab8646fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_backticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba4c0d-ba2d-4eaf-8400-70c1d78ae787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
