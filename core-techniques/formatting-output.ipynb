{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474af0de-3f6c-4c88-acf2-c17ed7c6d0b5",
   "metadata": {},
   "source": [
    "# Techniques for Formatting LLM Output\n",
    "\n",
    "Hello everyone. Getting an LLM to produce factually correct content is only half the battle. For developers, that content is often useless unless it's also in a **perfectly structured format**. If you need a parsable JSON object or a valid SQL query, \"close enough\" simply doesn't work.\n",
    "\n",
    "This notebook will demonstrate some common techniques we use to control and format LLM output, progressing from simple requests to a robust, layered, professional workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436ede5-a028-4c39-bb5c-2144168eda62",
   "metadata": {},
   "source": [
    "## The Task and Helper Functions\n",
    "\n",
    "Our consistent task for this notebook will be to **analyze a user review and extract key information into a JSON object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e66281-6e98-4f3e-afa4-20af31a3f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"openai/gpt-4o-mini\"\n",
    "MAX_TOKENS_DEFAULT = 200\n",
    "\n",
    "def get_completion(\n",
    "    prompt,\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS_DEFAULT,\n",
    "    **kwargs\n",
    "):\n",
    "    parsed_messages = []\n",
    "\n",
    "    if type(prompt) is str:\n",
    "        parsed_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        parsed_messages = prompt\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=parsed_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"Setup complete. Helper functions and user review are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c56cd3-fcc5-401b-bb7d-d74253ebbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_REVIEW = dedent(\"\"\"\n",
    "    I am absolutely thrilled with my new 'QuantumLeap' server! It's faster than anything I've ever used.\n",
    "    The setup was a bit tricky, but the support team was fantastic. I'm giving it a 5 out of 5 stars.\n",
    "    Highly recommended for any serious data processing work.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6472c3-2bbd-40f0-b0e6-9852d840a55e",
   "metadata": {},
   "source": [
    "## Direct Instruction (The \"Please\" Method)\n",
    "\n",
    "This is the most basic approach: simply tell the model what format you want. It's easy but can be unreliable for complex formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99457b70-8a45-481f-9359-c2f464c000ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006b128b-11e8-4012-980a-1c6ba0b9c19e",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting (The \"Show, Don't Tell\" Method)\n",
    "\n",
    "This is a major step up in reliability. We *show* the model the exact format we want by providing a high-quality example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb155b4-35a7-4d80-ae6d-514a29700040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7abde22a-3cca-4278-8714-2d7ed194e694",
   "metadata": {},
   "source": [
    "## Providing a Template (The \"Fill in the Blanks\" Method)\n",
    "\n",
    "This technique gives the model even less room for error. We provide the exact structure and ask the model to fill in the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739f921-e09f-43be-9ea5-4de1b75bf5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a381206e-9b20-4382-9618-8afae94d13e9",
   "metadata": {},
   "source": [
    "## API-Level Enforcement\n",
    "\n",
    "This is the most robust method. We provide a clear schema and use the `response_format` parameter to **guarantee** the output will be a syntactically valid JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a5b5a-76ef-4a57-819f-a912c20f6b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13417139-2ba4-4541-bf0a-486b47f2c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
