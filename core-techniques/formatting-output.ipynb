{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474af0de-3f6c-4c88-acf2-c17ed7c6d0b5",
   "metadata": {},
   "source": [
    "# Techniques for Formatting LLM Output\n",
    "\n",
    "Hello everyone. Getting an LLM to produce factually correct content is only half the battle. For developers, that content is often useless unless it's also in a **perfectly structured format**. If you need a parsable JSON object or a valid SQL query, \"close enough\" simply doesn't work.\n",
    "\n",
    "This notebook will demonstrate some common techniques we use to control and format LLM output, progressing from simple requests to a robust, layered, professional workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436ede5-a028-4c39-bb5c-2144168eda62",
   "metadata": {},
   "source": [
    "## The Task and Helper Functions\n",
    "\n",
    "Our consistent task for this notebook will be to **analyze a user review and extract key information into a JSON object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e66281-6e98-4f3e-afa4-20af31a3f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"openai/gpt-4o-mini\"\n",
    "MAX_TOKENS_DEFAULT = 200\n",
    "\n",
    "def get_completion(\n",
    "    prompt,\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS_DEFAULT,\n",
    "    **kwargs\n",
    "):\n",
    "    parsed_messages = []\n",
    "\n",
    "    if type(prompt) is str:\n",
    "        parsed_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        parsed_messages = prompt\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=parsed_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"Setup complete. Helper functions and user review are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c56cd3-fcc5-401b-bb7d-d74253ebbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_REVIEW = dedent(\"\"\"\n",
    "    I am absolutely thrilled with my new 'QuantumLeap' server! It's faster than anything I've ever used.\n",
    "    The setup was a bit tricky, but the support team was fantastic. I'm giving it a 5 out of 5 stars.\n",
    "    Highly recommended for any serious data processing work.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6472c3-2bbd-40f0-b0e6-9852d840a55e",
   "metadata": {},
   "source": [
    "## Direct Instruction (The \"Please\" Method)\n",
    "\n",
    "This is the most basic approach: simply tell the model what format you want. It's easy but can be unreliable for complex formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99457b70-8a45-481f-9359-c2f464c000ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_v1 = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(f\"\"\"\n",
    "        Analyze the following user review and output your findings as JSON.\n",
    "        Include the product name, a short summary, and a sentiment score.\n",
    "\n",
    "        <review>\n",
    "        {USER_REVIEW}\n",
    "        </review>\n",
    "        \"\"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "response_v1 = get_completion(prompt_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a213e7-21db-4940-88d2-d4d5cc53eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b128b-11e8-4012-980a-1c6ba0b9c19e",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting (The \"Show, Don't Tell\" Method)\n",
    "\n",
    "This is a major step up in reliability. We *show* the model the exact format we want by providing a high-quality example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb155b4-35a7-4d80-ae6d-514a29700040",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_v2 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "        You are an expert review analyst.\n",
    "\n",
    "        Convert user reviews into a structured JSON following the provided examples.\n",
    "        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The 'StellarSSD' is ok, but the price is a bit too high.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": json.dumps({\n",
    "            \"product_name\": \"StellarSSD\",\n",
    "            \"summary\": \"The product is function but overpriced\",\n",
    "            \"sentiment_score\": 3\n",
    "        })\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": USER_REVIEW\n",
    "    }\n",
    "]\n",
    "\n",
    "response_v2 = get_completion(prompt_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179267d1-957f-46f1-b73a-d2c4356b89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abde22a-3cca-4278-8714-2d7ed194e694",
   "metadata": {},
   "source": [
    "## Providing a Template (The \"Fill in the Blanks\" Method)\n",
    "\n",
    "This technique gives the model even less room for error. We provide the exact structure and ask the model to fill in the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739f921-e09f-43be-9ea5-4de1b75bf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_template = {\n",
    "    \"product_name\": \"\",\n",
    "    \"summary\": \"\",\n",
    "    \"sentiment_score\": 0\n",
    "}\n",
    "\n",
    "prompt_v3 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": dedent(f\"\"\"\n",
    "        You are an expert review analyst.\n",
    "\n",
    "        Convert user reviews into a structured JSON following the provided template.\n",
    "\n",
    "        <template>\n",
    "        {json.dumps(json_template)}\n",
    "        </template>\n",
    "        \"\"\")\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": USER_REVIEW\n",
    "    }\n",
    "]\n",
    "\n",
    "response_v3 = get_completion(prompt_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcc8d8-c386-4e55-8d80-f7aabfd238a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381206e-9b20-4382-9618-8afae94d13e9",
   "metadata": {},
   "source": [
    "## API-Level Enforcement\n",
    "\n",
    "This is the most robust method. We provide a clear schema and use the `response_format` parameter to **guarantee** the output will be a syntactically valid JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a5b5a-76ef-4a57-819f-a912c20f6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_v4 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": dedent(\"\"\"\n",
    "        You are an expert review analyst.\n",
    "\n",
    "        Convert user reviews into a structured JSON following the schema:\n",
    "\n",
    "        {\n",
    "            \"product_name\": str,\n",
    "            \"summary\": str,\n",
    "            \"sentiment_score\": int(min=1, max=5)\n",
    "        }\n",
    "\n",
    "        If the received content is not a review, then respond with the following schema:\n",
    "\n",
    "        {\n",
    "            \"error\": str,\n",
    "            \"original_message\": str\n",
    "        }\n",
    "        \"\"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "response_v4 = get_completion(\n",
    "    prompt_v4 + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": USER_REVIEW\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "response_v4_error = get_completion(\n",
    "    prompt_v4 + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I'm feeling great today!\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13417139-2ba4-4541-bf0a-486b47f2c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_v4)\n",
    "print(response_v4_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390272b-fdca-4e6d-a275-18710d516510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
