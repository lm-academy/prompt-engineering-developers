{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef41276f-8f98-4ee3-93e0-e78dd4a333c5",
   "metadata": {},
   "source": [
    "# Chain-of-Thought - Forcing the LLM to \"Show Its Work\"\n",
    "\n",
    "Hello everyone. Let's dive into another impactful prompting technique: **Chain-of-Thought (CoT) Prompting**.\n",
    "\n",
    "The core idea is to counteract the model's natural tendency to \"rush\" to an answer. For any problem that requires logic, arithmetic, or multi-step reasoning, forcing the model to slow down and \"show its work\" dramatically improves its accuracy. This is particularly effective when working with lower-end LLMs (less reasoning capabilities).\n",
    "\n",
    "This is done by explicitly instructing the model to think step-by-step. This simple instruction creates a \"chain\" of reasoning where each thought builds on the last, leading to a more reliable conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea59244-ecd0-411d-abc9-5466ad972e76",
   "metadata": {},
   "source": [
    "## The Task and Helper Functions\n",
    "\n",
    "First, let's set up our helper functions and context data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30393f7c-9ee3-46cc-a759-6753d8c445fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import litellm\n",
    "from IPython.display import display, Markdown\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration & Context ---\n",
    "MODEL_NAME = \"openai/gpt-4o-mini\"\n",
    "MAX_TOKENS_DEFAULT = 500 # More tokens for reasoning + code\n",
    "\n",
    "# --- The \"messy\" code to be refactored ---\n",
    "def get_user_initials(user_data_list):\n",
    "    initials_list = []\n",
    "    for user in user_data_list:\n",
    "        if 'name' in user and len(user['name']) > 0:\n",
    "            parts = user['name'].split(' ')\n",
    "            initials = ''\n",
    "            for part in parts:\n",
    "                initials += part[0].upper()\n",
    "            initials_list.append(initials)\n",
    "    return initials_list\n",
    "\n",
    "CODE_TO_REFACTOR = inspect.getsource(get_user_initials)\n",
    "\n",
    "def get_completion(\n",
    "    prompt,\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=MAX_TOKENS_DEFAULT,\n",
    "    **kwargs\n",
    "):\n",
    "    parsed_messages = []\n",
    "\n",
    "    if type(prompt) is str:\n",
    "        parsed_messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        parsed_messages = prompt\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=model,\n",
    "        messages=parsed_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\"Setup complete. Helper functions and code context are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65dac67-c7a6-429b-9520-50f979a046f4",
   "metadata": {},
   "source": [
    "## Attempt 1: No Chain-of-Thought\n",
    "\n",
    "Let's first ask the model for a direct answer without guiding its thought process. This demonstrates the model's default \"fast thinking\" mode, which often produces only the final result and does not provide much information into how the model tackled the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37190f-ca19-4097-b65b-208b5be958c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_no_cot = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(f\"\"\"\n",
    "        Please refactor the following Python code:\n",
    "\n",
    "        ```python\n",
    "        {CODE_TO_REFACTOR}\n",
    "        ```\n",
    "        \"\"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "response_no_cot = get_completion(prompt_no_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1882ef8-18c7-42f1-b539-87ba86a40dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_no_cot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6a42f-08a2-4b60-9ff4-a1b43bc3da9e",
   "metadata": {},
   "source": [
    "## Attempt 2: Introducing Chain-of-Thought\n",
    "\n",
    "For maximum reliability on complex, repeatable tasks, we can use **Chain-of-Thought**, which can become even more powerful when combined with a couple few-shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea94518-fcb2-4bf1-9ac1-abd095362781",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_cot = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": dedent(f\"\"\"\n",
    "        Please refactor the following Python code.\n",
    "        Let's think step by step and please provide your reasoning.\n",
    "        \n",
    "        While solving the problem, consider, among others, documentation, typing, readibility, etc.\n",
    "\n",
    "        ```python\n",
    "        {CODE_TO_REFACTOR}\n",
    "        ```\n",
    "        \"\"\")\n",
    "    }\n",
    "]\n",
    "\n",
    "response_with_cot = get_completion(prompt_with_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b60cc-65ce-4e61-8d11-be5fdae9d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_with_cot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b7702-2c43-4dbc-957e-617fff70bc84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
